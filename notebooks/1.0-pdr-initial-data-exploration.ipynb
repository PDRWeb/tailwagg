{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Exploration\n",
    "\n",
    "This notebook contains the initial exploration of the TailWagg pet retail dataset, including:\n",
    "- Database connection setup\n",
    "- Basic data loading and inspection\n",
    "- Initial product analysis\n",
    "- Data quality checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T06:11:24.374162Z",
     "iopub.status.busy": "2025-10-22T06:11:24.373625Z",
     "iopub.status.idle": "2025-10-22T06:11:27.686724Z",
     "shell.execute_reply": "2025-10-22T06:11:27.685842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/paulrodriguez/Documents/Documents - Paul’s MacBook Pro/Data Analyst School/_DataCamp/github/tailwagg\n",
      "Python path includes: True\n"
     ]
    }
   ],
   "source": [
    "# Add project root to Python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root directory (parent of notebooks directory)\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Add project root to Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path includes: {project_root in sys.path}\")\n",
    "\n",
    "# Import TailWagg utilities\n",
    "from src.utils.database import get_database_engine, test_connection\n",
    "from src.dataset import load_daily_metrics\n",
    "from src.utils.validation import validate_environment\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure SQLAlchemy Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T06:11:27.696754Z",
     "iopub.status.busy": "2025-10-22T06:11:27.696461Z",
     "iopub.status.idle": "2025-10-22T06:11:27.914610Z",
     "shell.execute_reply": "2025-10-22T06:11:27.914015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL successfully!\n"
     ]
    }
   ],
   "source": [
    "# Validate environment and get database engine\n",
    "validate_environment()\n",
    "engine = get_database_engine()\n",
    "\n",
    "# Test connection\n",
    "if test_connection(engine):\n",
    "    print(\"Connected to PostgreSQL successfully!\")\n",
    "else:\n",
    "    print(\"Failed to connect to PostgreSQL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T06:11:27.916919Z",
     "iopub.status.busy": "2025-10-22T06:11:27.916668Z",
     "iopub.status.idle": "2025-10-22T06:11:30.917006Z",
     "shell.execute_reply": "2025-10-22T06:11:30.916265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily metrics data loaded:\n",
      "Shape: (216425, 9)\n",
      "Date range: 2022-10-17 00:00:00 to 2025-10-16 00:00:00\n",
      "Unique products: 457\n",
      "Unique categories: 5\n",
      "\n",
      "Data summary:\n",
      "                          order_date  total_units_sold  gross_revenue  \\\n",
      "count                         216425         216425.00      216425.00   \n",
      "mean   2024-04-05 14:10:24.005544448              1.78          61.50   \n",
      "min              2022-10-17 00:00:00              1.00           1.67   \n",
      "25%              2023-07-22 00:00:00              1.00          22.95   \n",
      "50%              2024-04-20 00:00:00              2.00          44.84   \n",
      "75%              2024-12-05 00:00:00              2.00          80.14   \n",
      "max              2025-10-16 00:00:00             11.00         690.02   \n",
      "std                              NaN              0.96          54.92   \n",
      "\n",
      "       total_discount       cogs  gross_profit  \n",
      "count       216425.00  216425.00     216425.00  \n",
      "mean             7.77      48.50         13.00  \n",
      "min              0.00       1.83       -120.15  \n",
      "25%              0.00      18.16          3.52  \n",
      "50%              2.18      35.32          8.95  \n",
      "75%              9.08      63.16         18.87  \n",
      "max            327.70     527.15        221.63  \n",
      "std             15.08      42.86         17.63  \n"
     ]
    }
   ],
   "source": [
    "# Load daily metrics using TailWagg utility\n",
    "df = load_daily_metrics()\n",
    "\n",
    "# Convert order_date to datetime for proper date handling\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "print(\"Daily metrics data loaded:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df['order_date'].min()} to {df['order_date'].max()}\")\n",
    "print(f\"Unique products: {df['product_id'].nunique()}\")\n",
    "print(f\"Unique categories: {df['category_name'].nunique()}\")\n",
    "print(\"\\nData summary:\")\n",
    "print(df.describe().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T06:11:30.919891Z",
     "iopub.status.busy": "2025-10-22T06:11:30.919664Z",
     "iopub.status.idle": "2025-10-22T06:11:30.965294Z",
     "shell.execute_reply": "2025-10-22T06:11:30.964599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample products from daily metrics:\n",
      "     product_id category_name\n",
      "0      prod_001        Treats\n",
      "501    prod_002        Treats\n",
      "999    prod_003      Wellness\n",
      "1467   prod_006   Accessories\n",
      "1954   prod_007      Wellness\n",
      "2410   prod_008        Treats\n",
      "2878   prod_009          Toys\n",
      "3346   prod_011   Accessories\n",
      "3807   prod_012   Accessories\n",
      "4250   prod_015          Toys\n"
     ]
    }
   ],
   "source": [
    "# Get sample products from the loaded data\n",
    "print(\"Sample products from daily metrics:\")\n",
    "sample_products = df[['product_id', 'category_name']].drop_duplicates().head(10)\n",
    "print(sample_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Quality Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T06:11:30.967918Z",
     "iopub.status.busy": "2025-10-22T06:11:30.967700Z",
     "iopub.status.idle": "2025-10-22T06:11:31.029660Z",
     "shell.execute_reply": "2025-10-22T06:11:31.028746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in daily metrics data:\n",
      "product_id              0\n",
      "category_name           0\n",
      "promo_id            85437\n",
      "order_date              0\n",
      "total_units_sold        0\n",
      "gross_revenue           0\n",
      "total_discount          0\n",
      "cogs                    0\n",
      "gross_profit            0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "product_id                  object\n",
      "category_name               object\n",
      "promo_id                    object\n",
      "order_date          datetime64[ns]\n",
      "total_units_sold             int64\n",
      "gross_revenue              float64\n",
      "total_discount             float64\n",
      "cogs                       float64\n",
      "gross_profit               float64\n",
      "dtype: object\n",
      "\n",
      "Unique values in key columns:\n",
      "Unique products: 457\n",
      "Date range: 2022-10-17 00:00:00 to 2025-10-16 00:00:00\n",
      "Unique categories: 5\n",
      "Unique promotions: 27\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in daily metrics data:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nUnique values in key columns:\")\n",
    "print(f\"Unique products: {df['product_id'].nunique()}\")\n",
    "print(f\"Date range: {df['order_date'].min()} to {df['order_date'].max()}\")\n",
    "print(f\"Unique categories: {df['category_name'].nunique()}\")\n",
    "print(f\"Unique promotions: {df['promo_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Database Tables to CSV\n",
    "\n",
    "Export all dimension and fact tables to the `data/raw/` directory for backup and version control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting database tables to CSV...\n",
      "============================================================\n",
      "✅ dim_category: 5 rows exported to dim_category.csv\n",
      "✅ dim_brand: 8 rows exported to dim_brand.csv\n",
      "✅ dim_channel: 7 rows exported to dim_channel.csv\n",
      "✅ dim_location: 5 rows exported to dim_location.csv\n",
      "✅ dim_customer: 6,000 rows exported to dim_customer.csv\n",
      "✅ dim_promo: 39 rows exported to dim_promo.csv\n",
      "✅ dim_product: 600 rows exported to dim_product.csv\n",
      "✅ fact_sales: 246,369 rows exported to fact_sales.csv\n",
      "✅ fact_ad_spend: 2,192 rows exported to fact_ad_spend.csv\n",
      "✅ fact_email: 3,801 rows exported to fact_email.csv\n",
      "✅ fact_inventory_snapshots: 78,500 rows exported to fact_inventory_snapshots.csv\n",
      "✅ fact_returns: 17,871 rows exported to fact_returns.csv\n",
      "============================================================\n",
      "Export complete!\n"
     ]
    }
   ],
   "source": [
    "# Export all database tables to CSV files\n",
    "# Ensure the data/raw directory exists\n",
    "os.makedirs(os.path.join(project_root, 'data', 'raw'), exist_ok=True)\n",
    "\n",
    "# Define all tables to export\n",
    "dimension_tables = [\n",
    "    'dim_category',\n",
    "    'dim_brand', \n",
    "    'dim_channel',\n",
    "    'dim_location',\n",
    "    'dim_customer',\n",
    "    'dim_promo',\n",
    "    'dim_product'\n",
    "]\n",
    "\n",
    "fact_tables = [\n",
    "    'fact_sales',\n",
    "    'fact_ad_spend',\n",
    "    'fact_email',\n",
    "    'fact_inventory_snapshots',\n",
    "    'fact_returns'\n",
    "]\n",
    "\n",
    "all_tables = dimension_tables + fact_tables\n",
    "\n",
    "# Export each table to CSV\n",
    "print(\"Exporting database tables to CSV...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for table_name in all_tables:\n",
    "    try:\n",
    "        # Read table from database\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df_table = pd.read_sql(query, engine)\n",
    "        \n",
    "        # Define output path\n",
    "        output_path = os.path.join(project_root, 'data', 'raw', f'{table_name}.csv')\n",
    "        \n",
    "        # Export to CSV\n",
    "        df_table.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"✅ {table_name}: {len(df_table):,} rows exported to {table_name}.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {table_name}: Export failed - {e}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Export complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
